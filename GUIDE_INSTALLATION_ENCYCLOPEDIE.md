# üìñ GUIDE COMPLET DE MISE EN PLACE DE L'ENCYCLOP√âDIE AUTOMOBILE

Ce guide explique **√©tape par √©tape** comment mettre en place tout le syst√®me d'encyclop√©die automobile avec scraping automatique depuis Internet.

---

## üéØ VUE D'ENSEMBLE

Le syst√®me collecte automatiquement depuis Internet :
- ‚úÖ **TOUTES les marques automobiles** (100-200 marques mondiales)
- ‚úÖ **TOUS les mod√®les** pour chaque marque (2000-5000+ mod√®les)
- ‚úÖ **TOUS les moteurs** avec specs compl√®tes (100-200 moteurs)
- ‚úÖ **TOUTES les transmissions** avec fiabilit√© (30-50 bo√Ætes)
- ‚úÖ **TOUS les avis r√©els** (avantages/inconv√©nients depuis forums)

### Relations dans la base de donn√©es :
- üîó **Marque** ‚Üî **Mod√®les** (une marque a plusieurs mod√®les)
- üîó **Mod√®le** ‚Üî **Moteurs** (un mod√®le peut avoir plusieurs moteurs)
- üîó **Mod√®le** ‚Üî **Transmissions** (un mod√®le peut avoir plusieurs bo√Ætes)
- üîó **Moteur** ‚Üî **Transmissions** (quelles bo√Ætes vont avec quel moteur)

---

## üìã PR√âREQUIS

### Syst√®me
- **PostgreSQL** install√© et d√©marr√©
- **Python 3.9+** install√©
- **Node.js 18+** install√© (pour le frontend)
- **Git** install√©

### V√©rifier PostgreSQL
```bash
# Windows
pg_ctl status

# Linux/Mac
sudo systemctl status postgresql
```

---

## üöÄ INSTALLATION √âTAPE PAR √âTAPE

### √âTAPE 1 : Cloner le projet et installer les d√©pendances

```bash
# Cloner le projet (si pas d√©j√† fait)
cd /chemin/vers/recherche_auto

# Backend - Installer les d√©pendances Python
cd backend
pip install -r requirements.txt

# Frontend - Installer les d√©pendances Node
cd ../frontend
npm install
```

### √âTAPE 2 : Configuration de la base de donn√©es

```bash
# Retour au backend
cd ../backend

# Cr√©er le fichier .env s'il n'existe pas
cat > .env << EOF
DATABASE_URL=postgresql://user:password@localhost:5432/recherche_auto
EOF
```

‚ö†Ô∏è **IMPORTANT** : Remplace `user`, `password` et `recherche_auto` par tes vraies valeurs !

### √âTAPE 3 : Cr√©er la base de donn√©es

```bash
# Connexion √† PostgreSQL
psql -U postgres

# Dans psql :
CREATE DATABASE recherche_auto;
\q
```

### √âTAPE 4 : Appliquer les migrations Alembic

```bash
# Depuis le dossier backend/

# V√©rifier les migrations disponibles
alembic history

# Appliquer TOUTES les migrations
alembic upgrade head
```

Tu devrais voir :
```
INFO  [alembic.runtime.migration] Running upgrade  -> df5ee69f89fe, initial
INFO  [alembic.runtime.migration] Running upgrade df5ee69f89fe -> a1b2c3d4e5f6, add car encyclopedia tables
INFO  [alembic.runtime.migration] Running upgrade a1b2c3d4e5f6 -> b1c2d3e4f5g6, add encyclopedia relations tables
```

‚úÖ **V√©rification** : Ta base de donn√©es a maintenant TOUTES les tables !

### √âTAPE 5 : V√©rifier les tables cr√©√©es

```bash
# Connexion √† la base
psql -U user -d recherche_auto

# Lister les tables
\dt

# Tu devrais voir :
# car_brands
# car_models
# engines
# transmissions
# engine_model_associations
# transmission_model_associations
# engine_transmission_associations
# technical_specifications
# brand_reviews
# model_reviews
# engine_reviews
# transmission_reviews

\q
```

---

## üåê COLLECTE DES DONN√âES DEPUIS INTERNET

### M√âTHODE 1 : Scraper COMPLET (RECOMMAND√â)

Ce script collecte **TOUT** automatiquement :

```bash
cd backend

# Lancer le scraper complet
python scrape_complete_encyclopedia.py
```

Ce script va :
1. ‚úÖ Collecter TOUTES les marques depuis Wikipedia, Automobile-Catalog, CarLogos
2. ‚úÖ Pour chaque marque : historique, r√©putation, avis
3. ‚úÖ Pour chaque marque : TOUS les mod√®les
4. ‚úÖ Pour chaque mod√®le : TOUTES les caract√©ristiques techniques
5. ‚úÖ Pour chaque mod√®le : TOUS les avis Caradisiac et forums
6. ‚úÖ Sauvegarder automatiquement dans la base

‚è±Ô∏è **Temps estim√©** : 10-15 heures (tu peux le laisser tourner toute la nuit)

### M√âTHODE 2 : Scrapers s√©par√©s (par cat√©gorie)

Si tu veux lancer les scrapers s√©par√©ment :

```bash
# 1. Mod√®les avec caract√©ristiques et avis
python scrape_models_web.py

# 2. Moteurs avec specs et fiabilit√©
python scrape_engines_web.py

# 3. Transmissions avec fiabilit√©
python scrape_transmissions_web.py
```

### M√âTHODE 3 : Script orchestrateur

```bash
# Lance tous les scrapers en s√©quence avec statistiques
python run_all_scrapers.py
```

---

## üîó CR√âER LES LIENS ENTRE LES DONN√âES

Apr√®s la collecte, il faut cr√©er les associations entre moteurs, mod√®les et transmissions.

### Script de liaison (√† cr√©er)

```bash
cd backend
python link_engines_models_transmissions.py
```

Ce script va :
1. Analyser les donn√©es collect√©es
2. Cr√©er les liens moteur ‚Üî mod√®le
3. Cr√©er les liens transmission ‚Üî mod√®le
4. Cr√©er les liens moteur ‚Üî transmission

---

## üìä V√âRIFIER LES DONN√âES

```bash
# Connexion √† la base
psql -U user -d recherche_auto

# Compter les marques
SELECT COUNT(*) FROM car_brands;

# Compter les mod√®les
SELECT COUNT(*) FROM car_models;

# Compter les moteurs
SELECT COUNT(*) FROM engines;

# Compter les transmissions
SELECT COUNT(*) FROM transmissions;

# V√©rifier les liens moteur-mod√®le
SELECT COUNT(*) FROM engine_model_associations;

# Voir quels moteurs pour un mod√®le sp√©cifique
SELECT e.name, e.power_hp, e.fuel_type
FROM engines e
JOIN engine_model_associations ema ON e.id = ema.engine_id
JOIN car_models cm ON ema.model_id = cm.id
WHERE cm.name = 'Clio V';

# Voir dans quels mod√®les un moteur est √©quip√©
SELECT cm.name, cb.name as brand
FROM car_models cm
JOIN car_brands cb ON cm.brand_id = cb.id
JOIN engine_model_associations ema ON cm.id = ema.model_id
JOIN engines e ON ema.engine_id = e.id
WHERE e.name = 'TCe 130';

\q
```

---

## üöÄ D√âMARRER L'APPLICATION

### Backend (API)

```bash
cd backend

# D√©marrer FastAPI
uvicorn app.main:app --reload --port 8000
```

L'API sera accessible sur : `http://localhost:8000`

### Frontend (React)

```bash
cd frontend

# D√©marrer le serveur de d√©veloppement
npm run dev
```

Le frontend sera accessible sur : `http://localhost:5173`

---

## üîç UTILISER L'ENCYCLOP√âDIE

### Via l'interface web

1. Ouvre `http://localhost:5173`
2. Va sur la page "Encyclop√©die"
3. Explore :
   - üöó **Marques** : Liste compl√®te avec r√©putation
   - üöò **Mod√®les** : Filtres par marque, segment, prix
   - üîß **Moteurs** : Filtres par type, puissance, fiabilit√©
   - ‚öôÔ∏è **Transmissions** : Filtres par type, fiabilit√©

### Via l'API

```bash
# Toutes les marques
curl http://localhost:8000/encyclopedia/brands

# Tous les mod√®les d'une marque
curl http://localhost:8000/encyclopedia/models?brand_id=renault-id

# D√©tails d'un mod√®le avec ses moteurs et transmissions
curl http://localhost:8000/encyclopedia/models/clio-v-id

# Tous les mod√®les √©quip√©s d'un moteur
curl http://localhost:8000/encyclopedia/engines/tce-130-id/models

# Toutes les transmissions pour un moteur
curl http://localhost:8000/encyclopedia/engines/tce-130-id/transmissions
```

---

## üìà EXEMPLES DE REQU√äTES UTILES

### Trouver tous les mod√®les avec un moteur sp√©cifique

```python
# Dans un script Python
from app.models import Engine, CarModel
from app.database import SessionLocal

db = SessionLocal()

# R√©cup√©rer le moteur TCe 130
engine = db.query(Engine).filter(Engine.name == "TCe 130").first()

# Tous les mod√®les √©quip√©s de ce moteur
if engine:
    models = engine.models  # Gr√¢ce √† la relation many-to-many !
    for model in models:
        print(f"- {model.brand.name} {model.name}")
```

### Trouver toutes les transmissions pour un mod√®le

```python
# R√©cup√©rer un mod√®le
model = db.query(CarModel).filter(CarModel.name == "Clio V").first()

# Toutes les transmissions disponibles
if model:
    transmissions = model.transmissions
    for trans in transmissions:
        print(f"- {trans.name} ({trans.type})")
```

### Trouver les combinaisons moteur-bo√Æte

```python
# R√©cup√©rer un moteur
engine = db.query(Engine).filter(Engine.name == "TDI 150").first()

# Toutes les bo√Ætes compatibles
if engine:
    transmissions = engine.transmissions
    for trans in transmissions:
        print(f"- {trans.name}")
```

---

## ‚ö†Ô∏è D√âPANNAGE

### Probl√®me : "Relation does not exist"

```bash
# R√©appliquer les migrations
cd backend
alembic downgrade base
alembic upgrade head
```

### Probl√®me : "Could not connect to database"

```bash
# V√©rifier que PostgreSQL est d√©marr√©
# Windows
pg_ctl status

# Linux
sudo systemctl status postgresql

# D√©marrer PostgreSQL si n√©cessaire
sudo systemctl start postgresql
```

### Probl√®me : "No module named 'app'"

```bash
# S'assurer d'√™tre dans le dossier backend/
cd backend

# R√©installer les d√©pendances
pip install -r requirements.txt
```

### Probl√®me : Scraping bloqu√©

- Certains sites peuvent bloquer apr√®s trop de requ√™tes
- Le script respecte des d√©lais (2-3 secondes entre requ√™tes)
- Si bloqu√© : attendre 1 heure et relancer

---

## üìù MISE √Ä JOUR DES DONN√âES

Pour mettre √† jour l'encyclop√©die avec de nouvelles donn√©es :

```bash
# Relancer le scraper complet
python scrape_complete_encyclopedia.py

# Ou scrapers individuels
python scrape_models_web.py
python scrape_engines_web.py
python scrape_transmissions_web.py
```

Les donn√©es existantes seront mises √† jour ou compl√©t√©es.

---

## üéâ R√âSULTAT FINAL

Apr√®s avoir suivi ce guide, tu auras :

‚úÖ Une base de donn√©es compl√®te avec :
   - 100-200 marques automobiles
   - 2000-5000+ mod√®les
   - 100-200 moteurs
   - 30-50 transmissions
   - TOUS les liens entre eux

‚úÖ Toutes les caract√©ristiques techniques de chaque mod√®le

‚úÖ Tous les avis r√©els (avantages/inconv√©nients)

‚úÖ Une API REST compl√®te pour interroger les donn√©es

‚úÖ Une interface web pour explorer l'encyclop√©die

‚úÖ La possibilit√© de savoir :
   - Quels moteurs √©quipent un mod√®le
   - Dans quels mod√®les un moteur est utilis√©
   - Quelles transmissions vont avec un moteur
   - Tous les avis sur n'importe quel √©l√©ment

---

## üÜò SUPPORT

En cas de probl√®me :

1. V√©rifier les logs de l'API : `backend/logs/`
2. V√©rifier la console du scraper pour les erreurs
3. V√©rifier que PostgreSQL est bien d√©marr√©
4. V√©rifier que toutes les migrations sont appliqu√©es : `alembic current`

---

## üìö DOCUMENTATION SUPPL√âMENTAIRE

- **API** : `http://localhost:8000/docs` (Swagger UI automatique)
- **Scraping** : Voir `backend/SCRAPING_README.md`
- **Relations** : Voir `backend/app/models.py`

---

**üéØ TU ES PR√äT ! Lance le scraper et laisse-le collecter toutes les donn√©es !**
