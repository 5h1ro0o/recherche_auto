#!/usr/bin/env python3
"""
SCRIPT PRINCIPAL DE SCRAPING - VERSION SIMPLIFIÃ‰E
Lance tous les scrapers dans le bon ordre pour peupler l'encyclopÃ©die automobile
"""

import asyncio
import sys
from datetime import datetime


def print_banner():
    """BanniÃ¨re de dÃ©marrage"""
    print("\n" + "=" * 80)
    print("ğŸŒ SCRAPING ENCYCLOPÃ‰DIE AUTOMOBILE COMPLÃˆTE".center(80))
    print("=" * 80 + "\n")


def print_section(title: str, emoji: str):
    """Affiche une section"""
    print(f"\n{'=' * 80}")
    print(f"{emoji} {title}")
    print("=" * 80 + "\n")


async def scrape_brands_and_models():
    """
    Ã‰TAPE 1 : Collecte des marques et modÃ¨les
    Utilise le scraper amÃ©liorÃ© testÃ© et fonctionnel
    """
    print_section("Ã‰TAPE 1/3 : MARQUES ET MODÃˆLES", "ğŸš—")

    print("ğŸ“Œ Utilisation du scraper amÃ©liorÃ© (scrape_encyclopedia_improved.py)")
    print("ğŸ“Š DonnÃ©es : 57 marques + 155 modÃ¨les")
    print("â±ï¸  DurÃ©e estimÃ©e : 2-5 minutes\n")

    try:
        from scrape_encyclopedia_improved import ImprovedScraper

        scraper = ImprovedScraper()
        await scraper.run_complete_scraping()

        print("\nâœ… Marques et modÃ¨les collectÃ©s avec succÃ¨s !")
        return True

    except Exception as e:
        print(f"\nâŒ Erreur lors de la collecte des marques/modÃ¨les : {e}")
        import traceback
        traceback.print_exc()
        return False


async def scrape_engines():
    """
    Ã‰TAPE 2 : Collecte des moteurs (optionnel)
    """
    print_section("Ã‰TAPE 2/3 : MOTEURS (OPTIONNEL)", "ğŸ”§")

    print("âš ï¸  Cette Ã©tape est optionnelle et peut prendre du temps.")
    print("ğŸ“Š DonnÃ©es : 100-200 moteurs avec specs et fiabilitÃ©")
    print("â±ï¸  DurÃ©e estimÃ©e : 30-60 minutes")

    # Pour l'instant, on skip cette Ã©tape car les autres scrapers
    # peuvent avoir des erreurs 403
    print("\nâ­ï¸  Passage Ã  l'Ã©tape suivante (Ã  implÃ©menter plus tard)")
    print("ğŸ’¡ Conseil : Utilisez scrape_engines_web.py sÃ©parÃ©ment si besoin\n")
    return True


async def scrape_transmissions():
    """
    Ã‰TAPE 3 : Collecte des transmissions (optionnel)
    """
    print_section("Ã‰TAPE 3/3 : TRANSMISSIONS (OPTIONNEL)", "âš™ï¸")

    print("âš ï¸  Cette Ã©tape est optionnelle et peut prendre du temps.")
    print("ğŸ“Š DonnÃ©es : 30-50 transmissions avec fiabilitÃ©")
    print("â±ï¸  DurÃ©e estimÃ©e : 30-60 minutes")

    # Pour l'instant, on skip cette Ã©tape
    print("\nâ­ï¸  Passage au rÃ©sumÃ© (Ã  implÃ©menter plus tard)")
    print("ğŸ’¡ Conseil : Utilisez scrape_transmissions_web.py sÃ©parÃ©ment si besoin\n")
    return True


def print_summary(success: bool, duration: float):
    """Affiche le rÃ©sumÃ© final"""
    print("\n" + "=" * 80)
    print("ğŸ“Š RÃ‰SUMÃ‰ FINAL".center(80))
    print("=" * 80 + "\n")

    if success:
        print("âœ… Scraping terminÃ© avec succÃ¨s !")
        print("\nğŸ“ˆ DonnÃ©es collectÃ©es :")
        print("   â€¢ 57 marques automobiles")
        print("   â€¢ 155 modÃ¨les de voitures")
        print("   â€¢ Relations marque â†” modÃ¨le crÃ©Ã©es")

        print(f"\nâ±ï¸  DurÃ©e totale : {duration:.1f} secondes")

        print("\nğŸ¯ PROCHAINES Ã‰TAPES :")
        print("   1. VÃ©rifier les donnÃ©es : psql -U postgres -d recherche_auto")
        print("   2. DÃ©marrer l'API : uvicorn app.main:app --reload")
        print("   3. Tester le frontend : cd ../frontend && npm run dev")

        print("\nğŸ’¡ POUR ALLER PLUS LOIN :")
        print("   â€¢ Ajouter plus de modÃ¨les : python scrape_models_web.py")
        print("   â€¢ Ajouter des moteurs : python scrape_engines_web.py")
        print("   â€¢ Ajouter des transmissions : python scrape_transmissions_web.py")
    else:
        print("âŒ Le scraping a rencontrÃ© des erreurs")
        print("\nğŸ“‹ VÃ©rifications Ã  faire :")
        print("   â€¢ PostgreSQL est-il dÃ©marrÃ© ?")
        print("   â€¢ Les migrations sont-elles appliquÃ©es ? (alembic upgrade head)")
        print("   â€¢ Le fichier .env existe-t-il avec DATABASE_URL ?")

    print("\n" + "=" * 80 + "\n")


async def main():
    """Point d'entrÃ©e principal"""
    start_time = datetime.now()

    print_banner()
    print(f"ğŸ• DÃ©marrage : {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")

    try:
        # Ã‰TAPE 1 : Marques et modÃ¨les (obligatoire)
        success = await scrape_brands_and_models()

        if not success:
            print("\nâš ï¸  ArrÃªt du scraping suite Ã  une erreur critique")
            return 1

        # Ã‰TAPE 2 : Moteurs (optionnel)
        await scrape_engines()

        # Ã‰TAPE 3 : Transmissions (optionnel)
        await scrape_transmissions()

        # RÃ©sumÃ© final
        duration = (datetime.now() - start_time).total_seconds()
        print_summary(True, duration)

        return 0

    except KeyboardInterrupt:
        print("\n\nâš ï¸  Scraping interrompu par l'utilisateur (Ctrl+C)")
        return 1

    except Exception as e:
        print(f"\n\nâŒ Erreur fatale : {e}")
        import traceback
        traceback.print_exc()

        duration = (datetime.now() - start_time).total_seconds()
        print_summary(False, duration)
        return 1


if __name__ == "__main__":
    print("\n" + "ğŸš€ LANCEMENT DU SCRAPING AUTOMATIQUE".center(80))
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
