# ğŸŒ Web Scraping Automatique - EncyclopÃ©die Automobile

Ce dossier contient tous les scripts de web scraping pour collecter automatiquement TOUTES les donnÃ©es automobiles depuis Internet.

## ğŸ“‹ Scripts Disponibles

### 1. **scrape_models_web.py** - Scraping des modÃ¨les de voitures
Collecte automatiquement depuis :
- âœ… **API CarQuery** - SpÃ©cifications techniques
- âœ… **Automobile-Catalog** - Dimensions, performances, consommation
- âœ… **Caradisiac** - Avis utilisateurs, avantages/inconvÃ©nients
- âœ… **L'Argus** - Fiches techniques dÃ©taillÃ©es

**DonnÃ©es collectÃ©es** :
- Toutes les caractÃ©ristiques techniques (dimensions, poids, performances)
- Consommation rÃ©elle et Ã©missions CO2
- Avantages et inconvÃ©nients
- Avis clients rÃ©els
- Notes de fiabilitÃ©

### 2. **scrape_engines_web.py** - Scraping des moteurs
Collecte automatiquement depuis :
- âœ… **Sites techniques spÃ©cialisÃ©s** - SpÃ©cifications moteurs
- âœ… **Caradisiac FiabilitÃ©** - Notes de fiabilitÃ© et problÃ¨mes
- âœ… **Forums automobiles** - Retours d'expÃ©rience rÃ©els
- âœ… **L'Argus** - DonnÃ©es techniques et applications

**DonnÃ©es collectÃ©es** :
- SpÃ©cifications complÃ¨tes (cylindrÃ©e, puissance, couple, compression)
- Notes de fiabilitÃ© rÃ©elles
- Avantages et inconvÃ©nients
- ProblÃ¨mes communs recensÃ©s
- Avis d'experts et utilisateurs
- CoÃ»ts d'entretien

### 3. **scrape_transmissions_web.py** - Scraping des transmissions
Collecte automatiquement depuis :
- âœ… **Caradisiac** - FiabilitÃ© des boÃ®tes de vitesses
- âœ… **Forums spÃ©cialisÃ©s** - Retours utilisateurs
- âœ… **L'Argus** - SpÃ©cifications techniques
- âœ… **Sites techniques** - DÃ©tails constructeurs

**DonnÃ©es collectÃ©es** :
- Type et nombre de rapports
- Notes de fiabilitÃ©
- Avantages et inconvÃ©nients
- ProblÃ¨mes communs (embrayages, mÃ©catronique, etc.)
- CoÃ»ts de maintenance
- Avis utilisateurs rÃ©els

### 4. **run_all_scrapers.py** - Script principal
Lance tous les scrapers automatiquement en sÃ©quence avec statistiques dÃ©taillÃ©es.

## ğŸš€ Utilisation

### MÃ©thode 1 : Lancer tous les scrapers (RECOMMANDÃ‰)

```bash
# Depuis le dossier backend/
python run_all_scrapers.py
```

Ce script va :
1. ğŸš— Collecter tous les modÃ¨les pour toutes les marques
2. ğŸ”§ Collecter tous les moteurs (essence, diesel, hybride)
3. âš™ï¸  Collecter toutes les transmissions (manuelles, auto, robotisÃ©es)
4. ğŸ“Š Afficher les statistiques complÃ¨tes

### MÃ©thode 2 : Lancer les scrapers individuellement

```bash
# Uniquement les modÃ¨les
python scrape_models_web.py

# Uniquement les moteurs
python scrape_engines_web.py

# Uniquement les transmissions
python scrape_transmissions_web.py
```

## ğŸ“¦ DÃ©pendances

Toutes les dÃ©pendances sont dÃ©jÃ  dans `requirements.txt` :

```bash
pip install -r requirements.txt
```

Packages utilisÃ©s :
- `aiohttp` - RequÃªtes HTTP asynchrones
- `beautifulsoup4` - Parsing HTML
- `lxml` - Parser rapide pour BeautifulSoup
- `asyncio` - Programmation asynchrone

## âš™ï¸ Configuration

Les scrapers utilisent les variables d'environnement du fichier `.env` :

```env
DATABASE_URL=postgresql://user:password@localhost:5432/recherche_auto
```

## ğŸ“Š Sources de DonnÃ©es

### Sites de spÃ©cifications techniques
- **automobile-catalog.com** - Catalogue complet de vÃ©hicules
- **cars-data.com** - Base de donnÃ©es techniques
- **ultimatespecs.com** - SpÃ©cifications dÃ©taillÃ©es

### Sites d'avis et fiabilitÃ©
- **caradisiac.com** - Premier site auto franÃ§ais, forums trÃ¨s actifs
- **largus.fr** - L'Argus, rÃ©fÃ©rence historique
- **autoplus.fr** - Tests et essais dÃ©taillÃ©s
- **auto-moto.com** - Avis d'experts

### APIs automobiles
- **CarQuery API** - API gratuite de donnÃ©es automobiles
- **Auto-Data API** - SpÃ©cifications techniques

### Forums spÃ©cialisÃ©s
- **forum-auto.caradisiac.com** - Plus grand forum auto franÃ§ais
- **forum-peugeot.com** - Expertise Peugeot
- **forum-renault.com** - Expertise Renault
- **vwforum.com** - Expertise Volkswagen/Audi

## ğŸ¯ FonctionnalitÃ©s

### Scraping Intelligent
- âœ… **Retry automatique** avec backoff exponentiel
- âœ… **Respect des serveurs** (dÃ©lais entre requÃªtes)
- âœ… **Gestion des erreurs** robuste
- âœ… **Logging dÃ©taillÃ©** de la progression
- âœ… **Sauvegarde par batch** pour Ã©viter les pertes

### Extraction de DonnÃ©es
- âœ… **Parsing HTML** avec BeautifulSoup
- âœ… **Extraction intelligente** de nombres, textes, dates
- âœ… **Nettoyage automatique** des donnÃ©es
- âœ… **Fusion multi-sources** pour enrichissement

### Performance
- âœ… **Asynchrone** (aiohttp, asyncio)
- âœ… **ParallÃ©lisation** des requÃªtes
- âœ… **Session persistante** HTTP
- âœ… **Timeouts configurables**

## ğŸ“ˆ RÃ©sultats Attendus

Avec tous les scrapers, vous collecterez :

| CatÃ©gorie | QuantitÃ© estimÃ©e |
|-----------|-----------------|
| **ModÃ¨les** | 500-1000+ modÃ¨les |
| **Moteurs** | 100-200 moteurs |
| **Transmissions** | 30-50 boÃ®tes |
| **TOTAL** | **630-1250 entrÃ©es** |

## âš ï¸ Avertissements

### LÃ©galitÃ©
- âœ… Les scrapers respectent les `robots.txt`
- âœ… DÃ©lais entre requÃªtes pour ne pas surcharger les serveurs
- âœ… Usage strictement personnel/Ã©ducatif
- âš ï¸  VÃ©rifiez les CGU des sites scrapÃ©s

### Limitations
- â±ï¸  Le scraping complet peut prendre **2-4 heures**
- ğŸŒ Requiert une connexion Internet stable
- ğŸ“¡ Certains sites peuvent bloquer aprÃ¨s trop de requÃªtes
- ğŸ”„ Certaines donnÃ©es peuvent ne pas Ãªtre disponibles

### Maintenance
- ğŸ”§ Les sites changent rÃ©guliÃ¨rement leur structure HTML
- ğŸ”„ Les sÃ©lecteurs CSS/classes peuvent devenir obsolÃ¨tes
- âš™ï¸  Maintenance rÃ©guliÃ¨re des scrapers recommandÃ©e

## ğŸ› Debugging

### Activer les logs dÃ©taillÃ©s

Modifier `echo=True` dans les scripts pour voir les requÃªtes SQL :

```python
engine = create_async_engine(DATABASE_URL, echo=True)
```

### Tester sur une seule marque

Modifier dans `run_all_scrapers.py` :

```python
for brand_id, brand_name in brands[:1]:  # Tester sur 1 marque seulement
```

### Voir les requÃªtes HTTP

Les scrapers affichent dÃ©jÃ  :
- âœ… URLs visitÃ©es
- âœ… Status codes
- âœ… Erreurs de connexion

## ğŸ“ Exemple de sortie

```
================================================================================
                 SCRAPING AUTOMATIQUE ENCYCLOPÃ‰DIE AUTOMOBILE
                     Collecte TOUTES les donnÃ©es depuis Internet
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸš— SCRAPING DES MODÃˆLES AUTOMOBILES                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“‹ 57 marques trouvÃ©es
ğŸŒ Sources : CarQuery API, Automobile-Catalog, Caradisiac, L'Argus

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Marque: Renault
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ” Scraping automobile-catalog.com pour Renault...
âœ… Automobile Catalog: 45 modÃ¨les trouvÃ©s

ğŸ’¬ Scraping avis Caradisiac pour Renault Clio V...
âœ… Renault: 45 modÃ¨les collectÃ©s

...

================================================================================
                             STATISTIQUES FINALES
================================================================================

ğŸ“Š ModÃ¨les collectÃ©s      :    856
ğŸ“Š Moteurs collectÃ©s      :    142
ğŸ“Š Transmissions collectÃ©es:     38
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š TOTAL                  :   1036

âš ï¸  Erreurs               :      0

â±ï¸  DurÃ©e totale          : 02h 34m 18s

================================================================================

âœ… Scraping terminÃ© avec succÃ¨s !
```

## ğŸ¤ Contribution

Pour ajouter de nouvelles sources de donnÃ©es :

1. Identifier le site cible
2. Analyser la structure HTML
3. CrÃ©er les fonctions de scraping
4. Ajouter la gestion d'erreurs
5. Tester sur quelques exemples
6. IntÃ©grer dans le scraper principal

## ğŸ“ Support

En cas de problÃ¨me :
1. VÃ©rifier la connexion Internet
2. VÃ©rifier que PostgreSQL est dÃ©marrÃ©
3. VÃ©rifier les logs d'erreur
4. Tester sur une seule marque d'abord
5. VÃ©rifier que les sites sources sont accessibles

---

**Note** : Ce systÃ¨me de scraping collecte des donnÃ©es publiques pour un usage personnel/Ã©ducatif. Respectez toujours les conditions d'utilisation des sites web.
